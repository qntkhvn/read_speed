---
title: Analysis of CSV File Reading in R
author:
  - Quang Nguyen
  - Robert Tedesco
date: STAT 407 Fall 2021
output: 
  pdf_document: 
    number_sections: true
    df_print: kable
    keep_tex: true
# abstract: "write some stuff"
header-includes:
 \usepackage{setspace}
 \setlength{\parskip}{3mm}
 \onehalfspacing
 \usepackage{float}
 \floatplacement{figure}{H}
 \usepackage[skip=3pt]{caption}
bibliography: ref.bib
csl: apa.csl
indent: true
geometry: margin=1.1in
fontsize: 12pt
---

\begin{center}

\small

Abstract

\end{center}

\vspace{-8mm}

\small

> This manuscript is a statistical investigation into the impact of different factors on the time elapsed when importing CSV files into the \texttt{R} statistical computing language. We designed a $3^3$ factorial experiment with 20 replicates where our 
variables of interest were computer model, CSV file size, and `R` package/function. Our main findings are: 1) the `rio` package resulted in significantly different mean CSV reading times compared to the packages `readr` and `data.table`; 2) The Lenovo device had significantly lower mean reading times compared to the MacBook and Dell laptops; and 3) the average importing time differ for the three CSV files of sizes 0.49 GB, 1.22 GB, and 1.96 that we considered. Furthermore, a follow-up ANCOVA showed that `readr` is the most efficient package for loading CSV files into R on a MacBook.

\normalsize

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE,
                      echo = FALSE,
                      warning = FALSE,
                      fig.pos = "H")
```

```{r}
library(tidyverse)
theme_set(theme_bw())
library(patchwork)
library(broom)
library(car)
library(rcompanion)
```

```{r}
res <- bind_rows(read_csv("res_quang.csv"),
                 read_csv("res_rob.csv"),
                 read_csv("res_lance.csv")) %>% 
  mutate(computer = str_replace(computer, "lance", "dell"),
         computer = str_replace(computer, "rob", "lenovo"),
         computer = str_replace(computer, "quang", "mac"),
         
         across(where(is_character), factor))
```

\newpage

# Introduction

Data importing is undoubtedly a crucial part of a modern statistics and data science workflow, as it is the first step that paves the path for important stages such as data wrangling, visualizing, and modeling. With modern computers, loading data may seem like a straightforward task for a statistician. However, as the volume of data increases, this imposes a new set of challenges related to computing time and efficiency for data importing. A researcher may have to load a large data file multiple times a week in order to perform statistical analyses, which could potentially cost them valuable time. Identifying the fastest computing techniques is a necessity in the computational problem of working with big data.

The `R` programming language [@baser] is well-known among statisticians and data scientists as a powerful tool for working with data. In `R`, a popular method used by traditional statisticians to load a comma-separated values (CSV) file into the environment is `read.csv()`, which is a built-in base function. However, there are some drawbacks with this method, when working with large data sets. As demonstrated by @gregcsv, it took minutes to import a CSV file of about two-gigabyte containing over a million rows of NFL tracking data with the historical `read.csv()` function in base `R`. Fortunately, in recent years, `R` developers have come up with better ways to read in data files. As mentioned by @efficient in their "Efficient R programming" book, there are three modern functions/packages that `R` users should take advantage of in order to improve file-reading performance. 

The first function that `R` programmers should consider is `import()`, which comes from the `rio` package [@rio]. As described by its creators in the package documentation, `rio` is  "a swiss-army knife for data I/O".  The function `import()` in `rio` essentially simplifies the data importing process since as a function by itself, `import()` has the flexibility of reading in multiple file extensions, such as `.json`, `.xls`, `.xlsx`, in addition to the common `.csv`.  The data is stored as a `data.frame` object after being loaded into `R` in using `import()`.

Another `R` package for importing data that has gotten a lot of attention recently is `readr` [@readr], which is also part of the popular `tidyverse` collection of packages [@tidyverse] for modern data science. Within `readr`, there is a `read_csv()` function for getting CSV files into `R`, alongside other functions of the `read_*()` family designed for other file extensions. A notable aspect of the functions in `readr` in general and `read_csv()` in particular is the data is stored as a `tibble` (a "modern" `data.frame`-typed object) in the `R` environment once it is read in.

The third and final package for efficient file reading in `R` is `data.table` [@datatable], which contains the `fread()` function for data importing. As an individual function, `fread()` is also capable of loading a variety of file extensions, similar to `rio::import()`. As for object type, the `fread()` function imports and returns a data object of classes `data.table` and `data.frame`.

In this paper, we attempt to design a three-factor factorial experiment with replicates and perform analyses to compare the speed of the three CSV importing algorithms in `R` as mentioned in previous paragraphs. In particular, the independent variables we are interested in examining are 1) the `R` packages/functions; 2) the file size; and 3) the computer device. The paper is outlined as follows. We first describe our data generating process for our experiment and the methodologies used for analyses in Section 2. We then spend the next section, 3, on our analyses and results of this experiment. Lastly, in Section 4, we give a quick summary of our results as well as discuss possible future work related to this project.

# Experiment

The goal of this analysis is to determine the effects of three factors - `R` package, file size, computer device - on the reading time for CSV files measured in seconds. Because of this, we chose to design our experiment with a  $3^3$ factorial experiment [@montgomery] in mind. Furthermore, we chose to include $n=20$ replicates for each combination of our factors.  Our chosen design implies that the total number of observations for our experiment is 540. 

The three levels for each of our factors are described as follows. For our first factor, R functions and their associated packages, we considered the three package-function combinations as introduced in Section 1. This includes  `rio::import()`, `data.table::fread()`, and `readr::read_csv()`. As for our second variable, file size, we first utilized `R` to generate and export three CSV files of different sizes consisting of columns of randomly-draw samples from a standard normal distribution. First, the largest file consists of 1000000 rows and 100 columns and has a size of 0.49 GB. Next, we have a mid-sized file of 1.22 GB on disk containing 1000000 cases and 62 variables. Finally, our smallest CSV file has a row-by-column dimension of 252000 by 100 and takes up 1.96 GB of storage. Last but not least, we considered three different laptop devices for this experiment. In particular, we have a MacBook Air 2020 with an M1 processor, a Lenovo Legion 2019 with a Ryzen 7 4800H processor, and a Dell XPS 13 2020 with an  Intel i7 processor.

Our data was generated by considering the $3^3$ possible combinations of `R` package, file size, and computer. For each combination of reading function, file size, and device, we utilized the `R` function `Sys.time()` to measure the time it took to load the CSV file into our statistical software. We obtained the twenty replicates for each combination according to the order of a random sample of 1 through $3^3$.  

# Analysis of Variance

In this section, we present the analysis of variance for our designed experiment. First and foremost, in order to gain a better understanding of our data, we used interaction plots (see Figure 1) to observe that reading time varies for combinations of each factor. Interestingly, reading time seemed to increase significantly for all three packages when working with the largest data file (~2GB). `readr` seems to take longer than the other two packages considered when working with large data files. The Lenovo appeared to be faster than the Macbook and the Dell for all file sizes- the interaction does not appear significant. Lastly, the interaction of computer and package appears to be significant - the Macbook reads data quicker than the other computers using the `readr` package.

```{r}
p1 <- res %>% 
  group_by(size, package) %>% 
  summarize(avg_time = mean(time)) %>% 
  ungroup() %>% 
  ggplot(aes(size, avg_time)) +
  geom_line(size = 1, aes(group = package, color = package)) +
  geom_point(size = 2.5, aes(color = package), shape = 15) +
  theme(legend.position = "bottom")

p2 <- res %>% 
  group_by(size, computer) %>% 
  summarize(avg_time = mean(time)) %>% 
  ungroup() %>% 
  ggplot(aes(size, avg_time)) +
  geom_line(size = 1, aes(group = computer, color = computer)) +
  geom_point(size = 2.5, aes(color = computer), shape = 15) +
  theme(legend.position = "bottom")

p3 <- res %>% 
  group_by(package, computer) %>% 
  summarize(avg_time = mean(time)) %>% 
  ungroup() %>% 
  ggplot(aes(package, avg_time)) +
  geom_line(size = 1, aes(group = computer, color = computer)) +
  geom_point(size = 2.5, aes(color = computer), shape = 15) +
  theme(legend.position = "bottom")
```

```{r, fig.width=12, fig.height=4.5, fig.cap="Interaction plots between the variables size, computer, and package"}
p1 + p2 + p3
```

After gaining an understanding of our data, the next step was to fit the model corresponding to our experiment. The model for a three-level factorial experiment with three factors is given by \begin{equation} y_{ijkl} = \mu + \tau_i + \beta_j + \gamma_k + (\tau \beta)_{ij} + (\tau \gamma)_{ik} + (\beta \gamma)_{jk} + (\tau \beta \gamma)_{ijk} + \epsilon_{ijkl}, \end{equation} where $i, j , k = 1, 2, 3$ and $l = 1, 2, ...,20$, since we have $n=20$ replicates.

The response variable, $y_{ijkl}$, indicates the speed time in seconds corresponding to each run conducted in the experiment. Here $\mu$ represents the overall mean reading time,  and $\alpha_i$, $\beta_j$, and $\gamma_k$ are the main effects of three factors file size, computer device, and `R` function/package. There are also 3 two-factor and 1 three-factor interaction effects in our model. In addition, this model includes an error component $\epsilon_{ijkl}$, and the assumptions for the residuals are that they are normally distributed and the variance is constant across the groups. 

Using this model, we can conduct an ANOVA to see whether the levels in each factor significantly differ in mean data loading speed time. In addition, we can test for significance of each of the specified interaction effects. The model produced significant results (see Table 1), as all the terms in the ANOVA fit appear to have an effect on the response variable, data importing time. However, the residual assumptions are not met for this model, as illustrated by Figure 2 and Table 2. In particular, a normal probability plot followed by a Shapiro-Wilk test indicated a significant departure from normality for our model residuals. Moreover, a residuals versus fitted values plot and a Levene Test showed a violation of the equality of variances condition.

```{r}
mod <- lm(time ~ computer * size * package, data = res)
mod %>% 
  anova() %>% 
  tidy() %>% 
  mutate(across(where(is.numeric), ~ round(.x, 3))) %>% 
  knitr::kable(caption = "ANOVA for the three-factor factorial ANOVA model.")
```

```{r}
pqq <- tibble(resid = resid(mod)) %>% 
  ggplot(aes(sample = resid)) +
  stat_qq() + 
  stat_qq_line(linetype = "dashed")

prvf <- tibble(resid = resid(mod),
             fitted = fitted(mod)) %>% 
  ggplot(aes(fitted, resid)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed")
```

```{r, fig.width=6, fig.height=3, fig.cap="Residuals plots"}
pqq + prvf
```

```{r}
shap <- mod %>% 
  pluck("residuals") %>% 
  shapiro.test() %>% 
  tidy()
```

```{r}
lev <- leveneTest(time ~ computer * size * package, data = res) %>% 
  tidy() %>% 
  dplyr::select(-contains("df")) %>% 
  mutate(method = "Levene test for homogeneity of variance")
```

```{r}
shap %>% 
  bind_rows(lev) %>% 
  mutate(across(where(is.numeric), ~ round(.x, 3)),
         p.value = "0.000") %>% 
  knitr::kable(caption = "Shapiro-Wilk and Levene tests for the three-factor factorial ANOVA model.")
```

As a result of violations of normality and homoscedasticity, we then considered a couple of data transformation methods, namely, a natural log transformation and a Box-Cox power transformation [@boxcox] as possible ways to resolve the non-normality issue of our data. However, transforming the response variable, file reading time, did not improve the fit of this model and our assumptions are still not met. The ANOVA table, visual summary, and tests for normality and constant variance for these two methods can be found in the Appendix.

This then led us to look into a non-parametric alternative to the $3^3$ factorial model. We ended up using a permutation test for a three-way design, which does not assume a normal distribution for our data, and this is implemented via the function `perm.fact.test()` in the `asbio` `R` package [@asbio]. Table 3 shows the computer output for the permutation test for our three-factor factorial experiment. As we can see, since each factor and all interaction effects are significant, statisticians have a lot to keep in mind as they work with big data; certain machines may excel with certain packages and what package is best for reading data depends on the size of the file at hand. 

```{r}
perm.fact.test <- function(Y,
                           X1,
                           X2,
                           X3 = NA,
                           perm = 100,
                           method = "a") {
  if (all(is.na(X3))) {
    init.model <- anova(lm(Y ~ X1 * X2))
  }
  if (all(!is.na(X3))) {
    init.model <- anova(lm(Y ~ X1 * X2 * X3))
  }
  
  r <- length((init.model)$"F value") - 1
  F.init <- init.model$"F value"[1:r]
  MS <- init.model$"Mean Sq"
  
  # (a)
  if (method == "a") {
    F.perm <- matrix(nrow = r, ncol = perm)
    if (all(is.na(X3))) {
      for (i in 1:perm) {
        Y.new <- sample(Y, replace = FALSE)
        F.perm[, i] <- anova(lm(Y.new ~ X1 * X2))$"F value"[1:r]
      }
    }
    
    if (all(!is.na(X3))) {
      for (i in 1:perm) {
        Y.new <- sample(Y, replace = FALSE)
        F.perm[, i] <- anova(lm(Y.new ~ X1 * X2 * X3))$"F value"[1:r]
      }
    }
  }
  
  
  # (b)
  if (method == "b") {
    MS.perm <- matrix(nrow = r + 1, ncol = perm)
    if (all(is.na(X3))) {
      for (i in 1:perm) {
        Y.new <- sample(Y, replace = FALSE)
        MS.perm[, i] <- anova(lm(Y.new ~ X1 * X2))$"Mean Sq"
      }
    }
    
    if (all(!is.na(X3))) {
      for (i in 1:perm) {
        Y.new <- sample(Y, replace = FALSE)
        MS.perm[, i] <- anova(lm(Y.new ~ X1 * X2 * X3))$"Mean Sq"
      }
    }
    
    F.perm <- matrix(nrow = r, ncol = perm)
    for (i in 1:perm) {
      F.perm[, i] <- MS.perm[, i][1:r] / MS.perm[, i][r + 1]
    }
  }
  
  p1 <- matrix(nrow = r, ncol = perm)
  for (i in 1:r) {
    p1[i, ] <- F.perm[i, ] >= F.init[i]
  }
  
  p2 <- apply(p1, 1, function(x) {
    length(x[x == TRUE])
  })
  
  p.val <- (p2 + 1) / perm
  p.val <- ifelse(p.val > 1, 1, p.val)
  
  if (all(is.na(X3))) {
    Table <-
      data.frame(
        Initial.F = init.model$"F value",
        Df = init.model$"Df",
        row.names = c("X1", "X2", "X1:X2", "Residual"),
        pval = c(p.val, NA)
      )
  }
  if (all(!is.na(X3))) {
    Table <-
      tibble(
        Term = c(
          "X1",
          "X2",
          "X3",
          "X1:X2",
          "X1:X3",
          "X2:X3",
          "X1:X2:X3",
          "Residual"
        ),
        InitialF = init.model$"F value",
        DF = init.model$"Df",
        pval = c(p.val, NA)
      )
  }
  res <- list()
  res$Table <- Table
  res
}

set.seed(69)
perm <- perm.fact.test(Y = res$time,
                       X1 = res$size,
                       X2 = res$computer,
                       X3 = res$package,
                       perm = 9999)

perm$Table %>% 
  mutate(Term = str_replace(Term, "X1", "size"),
         Term = str_replace(Term, "X2", "computer"),
         Term = str_replace(Term, "X3", "package")) %>% 
  mutate(across(where(is.numeric), ~ round(.x, 3))) %>% 
  knitr::kable(caption = "Permutation test for the three-factor factorial ANOVA model.")
```

We then performed a pairwise permutation test to determine which pairs of levels in each of our three factors (file size, computer device, and function/package) differ significantly in terms of average file reading time. This was implemented using the `pairwisePermutationTest() ` function in the `rcompanion` `R` package. We observed that the two pairs of functions `data.table::fread()` - `rio::import()` and `rio::import()` - `readr::read_csv()` have different mean file importing time.  As for computer devices, Dell and MacBook don’t differ in data loading time, but they each have different mean reading times compared to Lenovo. Lastly, there is a difference in file importing time for all pairs of file sizes.

```{r}
pw1 <- pairwisePermutationTest(time ~ size, data = res, method = "fdr")
pw2 <- pairwisePermutationTest(time ~ computer, data = res, method = "fdr") 
pw3 <- pairwisePermutationTest(time ~ package, data = res, method = "fdr")

as_tibble(pw1) %>% 
  bind_rows(as_tibble(pw2)) %>% 
  bind_rows(as_tibble(pw3)) %>% 
  mutate(factor = c(rep("size", 3), rep("computer", 3), rep("package", 3))) %>% 
  select(factor, comparison = Comparison, statistic = Stat, p.value, p.adjust) %>% 
  mutate(across(where(is.numeric), ~ round(.x, 4))) %>% 
  knitr::kable(caption = "Pairwise comparisons using permutation tests with FDR adjustment for the three-factor factorial ANOVA model.")
```

# Additional Analysis

One particularly interesting observation we had after conducting analysis of variance to our data is that  `readr::read_csv()` is the fastest method when running on the MacBook device, but on the other hand, the slowest for the other two computers. This trend difference is depicted on the third plot of Figure 1. Thus, we are interested in performing a quick simulation study to see if there is a function/package effect on the file reading time for the MacBook device only. In addition to the three data files with sizes 0.49, 1.22, 1.96 GB used in the previous experiment, we simulated seven additional datasets with sizes 1.51, 1.73, 2.16, 2.36, 2.61, 2.94, 3.32 GB. After that we used each of the three methods (`read_csv()`, `import()`, `fread()`) to import the data files and record the time it took to read in. Figure 3 is a scatterplot of time elapsed and file size, broken down by CSV reading method, and it shows that `readr::read_csv()` is clearly the fastest data loading technique on the MacBook device.

```{r}
dat <- read_csv("add.csv") %>% 
  mutate(meth = factor(meth))
```

```{r, fig.height=3, fig.width=4, fig.cap="Scatterplot of time elapsed and file size, color coded by reading algorithm."}
dat %>% 
  ggplot(aes(size, elapsed, color = meth)) +
  geom_point() +
  geom_smooth(method = "lm", 
              size = 0.5,
              alpha = 0.3) +
  labs(x = "Size (GB)",
       y = "Time Elapsed (sec)",
       color = "Method") +
  scale_color_manual(values = c("midnightblue", "darkgreen", "darkorange2")) +
  theme(axis.title = element_text(size = 9),
        legend.text = element_text(size = 8),
        axis.text = element_text(size = 8),
        legend.title = element_text(size = 9))
```

\vspace{-3mm}

We then conducted an analysis of covariance (ANCOVA) with time elapsed as the response variable, the file reading function as the categorical independent variable, and the file size as the continuous covariate. The ANCOVA model is given by \begin{equation} y_{ij} = \mu + \tau_i + \beta(x_{ij} - \bar{x}_{\cdot \cdot}) + \epsilon_{ij}, \end{equation}
where $\tau_i$ is the effect of the $i$th treatment, and $\beta_j$ is a parameter associated with the $j$th subject. 

We were interested in using ANCOVA to investigate the effect of the packages/functions on the time elapsed. Table 5 suggests that the mean reading time differs among the CSV reading functions in `R`, after accounting for the effect of file size. Furthermore, both normality and constant variance conditions are met for this model, as illustrated by a Shapiro-Wilk test for normality and a Levene Test for homogeneity of variance (see Table 6).

```{r}
anc <- aov(elapsed ~ meth + size, data = dat)
a <- anc %>% 
  car::Anova(type = "III") %>% 
  tidy() %>% 
  mutate(across(where(is.numeric), ~ round(.x, 4)))

names(a) <- c("Term", "SS", "df", "F", "p-value")

a %>% 
  mutate(Term = str_replace(Term, "meth", "package")) %>% 
  knitr::kable(caption = "ANCOVA table for the analysis of reading time for different methods on MacBook device.")
```

```{r}
shap <- anc %>% 
  pluck("residuals") %>% 
  shapiro.test() %>% 
  tidy()
```

```{r}
lev <- leveneTest(elapsed ~ meth, data = dat) %>% 
  tidy() %>% 
  dplyr::select(-contains("df")) %>% 
  mutate(method = "Levene test for homogeneity of variance")
```

```{r}
shap %>% 
  bind_rows(lev) %>% 
  mutate(across(where(is.numeric), ~ round(.x, 3))) %>% 
  knitr::kable(caption = "Shapiro-Wilk and Levene tests for ANCOVA model.")
```

We can then proceed to perform multiple comparisons to see which algorithms are different from each other. It is confirmed by Table 7 that the mean reading time for `readr::read_csv()` is different (faster) than the mean reading time of the other two techniques, and the other two also don’t differ in terms of average importing time.

```{r}
library(multcomp)
glht(anc, linfct = mcp(meth = "Tukey")) %>% 
  tidy() %>% 
  mutate(across(where(is.numeric), ~ round(.x, 4))) %>% 
  dplyr::select(-null.value, -term) %>% 
  rename(se = std.error,
         `adj p-value` = adj.p.value) %>% 
  knitr::kable(caption = "Pairwise comparisons with Tukey contrasts following ANCOVA.")
```

# Conclusion and Discussion

In this paper, we examined the effects of three factors file size, computer device, and importing function on the reading time for CSV files in the `R` statistical programming language. While we could not conduct an ANOVA on our three-level factorial experiment due to the normality departures, we were still able to find results through a nonparametric permutation test. The results of our permutation test for the corresponding factorial design indicate that at least one level for all of the factors in our experiment (`R` package/function, file size, and computer) significantly differ in average reading speed time. In particular, the `rio` package resulted in significantly different mean CSV reading times compared to the packages `readr` and `data.table`. As for laptop device, the Lenovo machine had significantly lower mean importing times compared to the MacBook and Dell laptops. Lastly, the average time elapsed for loading CSV files into `R` differ across the three file sizes of 0.49 GB, 1.22 GB, and 1.96 GB. An additional analysis using ANCOVA suggests that `readr` is the most time-efficient package for getting CSV files into R on a MacBook Air with an M1 processor. 

In the wake of these results, we realize that there are numerous factors that we control for in future studies. While we ran this experiment with all three laptops on battery power, we hypothesize that there is a significant difference between file speeds for a plugged-in laptop versus a laptop on battery power. Another variable that may be significant is the size of memory within the user’s `R` environment. In addition, we could consider loading data in different environments, such as RStudio Desktop, RStudio Cloud, Google Colab Notebook, and Terminal/Command line. We could also look into the reading time for other forms of data files, such as `.tsv`, `.xlsx`, or `.json`. We also wonder if there is a significant difference in speed for techniques for reading other forms of data, such as image, text, or sound data. Future work may also include implementing a similar design with more than twenty replicates in order to improve the fit of the model and proceed with a parametric approach. Overall, this paper provides insight into the first step of the problem of working with big data- loading the data. Moving forward, more discussion between computer scientists and statisticians will allow us to more quickly fill computational pitfalls that arise when working with big data.

# Supplementary Material {-}

All materials related to this manuscript are publicly available on GitHub at \newline <https://github.com/qntkhvn/read_speed>.

# References {-}

<div id="refs"></div>

\newpage

# Appendix {-}

```{r}
mod <- lm(log(time) ~ computer * size * package, data = res)
mod %>% 
  anova() %>% 
  tidy() %>% 
  mutate(across(where(is.numeric), ~ round(.x, 3))) %>% 
  knitr::kable(caption = "ANOVA table for the three-factor factorial ANOVA model with a natural log transformation to the response.")
```

\vspace{-2mm}

```{r}
pqq <- tibble(resid = resid(mod)) %>% 
  ggplot(aes(sample = resid)) +
  stat_qq() + 
  stat_qq_line(linetype = "dashed")

prvf <- tibble(resid = resid(mod),
             fitted = fitted(mod)) %>% 
  ggplot(aes(fitted, resid)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed")
```

```{r, fig.width=6, fig.height=3, fig.cap="Residuals plots for the three-factor factorial ANOVA model with a natural log transformation to the response."}
pqq + prvf
```

```{r}
shap <- mod %>% 
  pluck("residuals") %>% 
  shapiro.test() %>% 
  tidy()
```

```{r}
lev <- leveneTest(log(time) ~ computer * size * package, data = res) %>% 
  tidy() %>% 
  dplyr::select(-contains("df")) %>% 
  mutate(method = "Levene test for homogeneity of variance")
```

\vspace{-4mm}

```{r}
shap %>% 
  bind_rows(lev) %>% 
  mutate(across(where(is.numeric), ~ round(.x, 3)),
         p.value = "0.000") %>% 
  knitr::kable(caption = "Shapiro-Wilk and Levene tests for the three-factor factorial ANOVA model with a natural log transformation to the response.")
```

```{r}
mod <- lm(time ^ (-0.2543644) ~ computer * size * package, data = res)
mod %>% 
  anova() %>% 
  tidy() %>% 
  mutate(across(where(is.numeric), ~ round(.x, 3))) %>% 
  knitr::kable(caption = "ANOVA table for the three-factor factorial ANOVA model with a Box-Cox transformation to the response.")
```

\vspace{-2mm}

```{r}
pqq <- tibble(resid = resid(mod)) %>% 
  ggplot(aes(sample = resid)) +
  stat_qq() + 
  stat_qq_line(linetype = "dashed")

prvf <- tibble(resid = resid(mod),
             fitted = fitted(mod)) %>% 
  ggplot(aes(fitted, resid)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed")
```

```{r, fig.width=6, fig.height=3, fig.cap="Residuals plots for the three-factor factorial ANOVA model with a Box-Cox transformation to the response."}
pqq + prvf
```

```{r}
shap <- mod %>% 
  pluck("residuals") %>% 
  shapiro.test() %>% 
  tidy()
```

```{r}
lev <- leveneTest(time ^ (-0.2543644) ~ computer * size * package, data = res) %>% 
  tidy() %>% 
  dplyr::select(-contains("df")) %>% 
  mutate(method = "Levene test for homogeneity of variance")
```

\vspace{-8mm}

```{r}
shap %>% 
  bind_rows(lev) %>% 
  mutate(across(where(is.numeric), ~ round(.x, 3)),
         p.value = "0.000") %>% 
  knitr::kable(caption = "Shapiro-Wilk and Levene tests for the three-factor factorial ANOVA model with a Box-Cox transformation to the response.")
```

\newpage

#   Individual Contributions {-}

Together we decided the topic, data collection process, wrote code for analyses (EDA, model fits, tests) and wrote the report. Rob wrote the abstract, experiment, analysis, and discussion sections of the report. Quang edited those sections, wrote the additional analysis section, and created tables and figures for the report. 
